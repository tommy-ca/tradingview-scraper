# Audit: Production-Parity Mini Smoke (Strict Scoreboard) — Run `20260105-154839`

## 1. Objective
Perform a strict-scoreboard oriented audit focused on:
1) **baseline correctness** (market/benchmark/raw_pool_ew fully instrumented in `audit.jsonl`), and  
2) **institutional gate behavior** (why strict candidates are empty, which gates are binding, and where the worst outliers live).

This run is intentionally small-scale but production-parity in windows/simulators/profile settings.

## 2. Run Definition
- Run ID: `20260105-154839`
- Dimensions (reduced grid):
  - Selection: `v3.2`
  - Rebalance: `window`
  - Engines: `custom` (plus always-on baseline engine `market`)
  - Profiles: `benchmark, hrp` (plus baseline profiles `market, benchmark, raw_pool_ew`)
  - Simulators: `custom, cvxportfolio, nautilus`
  - Windows: `train/test/step = 120/20/20` (production parity)

## 3. Artifact Map (Run-Scoped)
- Audit ledger: `artifacts/summaries/runs/20260105-154839/audit.jsonl`
- Tournament results: `artifacts/summaries/runs/20260105-154839/grand_4d_tournament_results.json`
- Run log: `artifacts/summaries/runs/20260105-154839/logs/grand_4d_tournament.log`
- Strict scoreboard outputs:
  - `artifacts/summaries/runs/20260105-154839/data/tournament_scoreboard.csv`
  - `artifacts/summaries/runs/20260105-154839/data/tournament_candidates.csv`
  - `artifacts/summaries/runs/20260105-154839/reports/research/tournament_scoreboard.md`

## 4. Audit Ledger Integrity & Completeness

### 4.1 Hash-chain integrity
- Verified via `uv run scripts/archive/verify_ledger.py artifacts/summaries/runs/20260105-154839/audit.jsonl`.

### 4.2 Event counts (expected vs observed)
This grid implies:
- `backtest_select`: `11 windows × (intent+success) = 22`
- `backtest_optimize`: `11 windows × 5 profiles × (intent+success) = 110`
  - 2× non-baseline: `custom/{benchmark,hrp}`
  - 3× baseline: `market/{market,benchmark,raw_pool_ew}`
- `backtest_simulate`: `11 windows × 5 profiles × 3 simulators = 165`
- `backtest_summary`: `5 profiles × 3 simulators = 15`

Observed counts match these expectations.

## 5. Baseline Correctness (Primary Goal)

### 5.1 Baseline optimize weights are now written into the ledger
The ledger now includes `backtest_optimize` intents + successes with non-empty `data.weights` for:
- `engine=market`, `profile=market`
- `engine=market`, `profile=benchmark`
- `engine=market`, `profile=raw_pool_ew`

Each appears once per window (11 total windows) and has a non-empty `weights` payload.

### 5.2 Scoreboard baseline rows are fully populated
In `data/tournament_scoreboard.csv`:
- Baseline rows: 9 (3 baseline profiles × 3 simulators)
- Baseline `selection_jaccard`: **9/9 non-null**
- Baseline `HHI`: **9/9 non-null**
- Baseline `n_assets`: **9/9 non-null**
- Baseline rows with `missing:selection_jaccard`: **0**

Observed baseline `selection_jaccard` values (constant across simulators by design):
- `market`: `1.0` (single holding; stable membership)
- `benchmark`: `≈ 0.546676`
- `raw_pool_ew`: `≈ 0.943791`

Interpretation: baseline rows are now treated as first-class strategies with complete stability + concentration diagnostics in strict scoreboards.

## 6. Strict Scoreboard Outcome (Institutional Gates)

### 6.1 Candidates
- `data/tournament_candidates.csv` is empty (0 rows). Strict gates veto every strategy configuration in this mini grid.

### 6.2 Veto frequency (non-baseline rows only)
For `engine=custom` (2 profiles × 3 simulators = 6 rows), the binding failures are:
- `temporal_fragility`: 6/6
- `af_dist`: 6/6
- `turnover`: 3/6 (HRP rows)
- `sim_parity`: 3/6 (HRP rows)
- `friction_decay`: 3/6 (benchmark rows)
- `stress_alpha`: 3/6 (benchmark rows)

### 6.3 Notable metric outliers (non-baseline)
- Temporal fragility: worst at `custom/benchmark/cvxportfolio` (`temporal_fragility ≈ 9.319651`)
- Friction decay (custom → cvx): `≈ 0.417055` for `custom/benchmark` (fails `max_friction_decay=0.30`)
- Parity gap (cvxportfolio vs nautilus): `≈ 0.027809` for `custom/hrp` (fails `max_parity_ann_return_gap=0.015`)
- Antifragility distribution (`af_dist`): negative across rows (fails `min_af_dist=0.0`)
- Stress alpha (`stress_alpha`): negative for benchmark (fails `min_stress_alpha=0.0`)
- Turnover: HRP turnover `≈ 0.5855` (fails `max_turnover=0.50`)

### 6.4 First-veto drivers (all rows, strict gate order)
The strict scoreboard appends failures in a deterministic order, so we can interpret the “first veto” as the earliest gate that fails:
- First veto `friction_decay`: 9/15 rows
  - All `benchmark` rows (`engine=custom` and `engine=market`, across 3 simulators)
  - All `raw_pool_ew` baseline rows (`engine=market`, across 3 simulators)
- First veto `temporal_fragility`: 6/15 rows
  - All `hrp` rows (`engine=custom`, across 3 simulators)
  - All `market` baseline rows (`engine=market`, across 3 simulators)

Implication: **strict candidate starvation is currently driven first by friction alignment and temporal fragility**, before secondary gates (AF/dist, stress alpha, turnover, parity) are even considered.

### 6.5 Window-level drivers of temporal fragility (CV of Sharpe)
For this run, temporal fragility is the coefficient of variation (CV) of per-window Sharpe.

The failures are not “slightly above threshold”; they are driven by **large Sharpe sign flips** and **large standard deviation relative to mean Sharpe**:

- `custom/benchmark`:
  - `custom` sim: mean Sharpe `≈ 0.579`, std `≈ 3.073`, CV `≈ 5.303`
  - `cvxportfolio` sim: mean Sharpe `≈ 0.338`, std `≈ 3.148`, CV `≈ 9.320`
  - Largest |Sharpe| windows (example): `2025-03-18` (~ -5.6 to -6.6), `2025-05-14` (~ +4.9 to +5.1)
- `custom/hrp`:
  - mean Sharpe `≈ 1.172–1.248`, std `≈ 3.86–3.97`, CV `≈ 3.18–3.29`
  - Largest |Sharpe| windows: `2025-03-18` (~ -6.5 to -7.2), `2025-12-03` (~ +4.8)
- Baseline `raw_pool_ew`:
  - `custom` sim: mean Sharpe `≈ 0.203`, std `≈ 3.794`, CV `≈ 18.676`
  - `cvxportfolio` sim: mean Sharpe `≈ -0.070`, std `≈ 4.229`, CV `≈ 60.848`

Interpretation: for any strategy whose mean Sharpe is small (near 0), CV-based fragility becomes extremely punitive. This is consistent with the metric definition, but it implies that a strict `max_temporal_fragility=1.5` gate can dominate tournaments even when annualized return is modestly positive.

### 6.6 Sign-flip audit (20d windows)
For `test_window=20`, we directly inspected per-window Sharpe series and found frequent sign flips (positive↔negative Sharpe) around the same “dominant” window transitions:

- Common flip cluster: `2025-05-14 → 2025-06-12` (largest ΔSharpe for several configs)
- Secondary flip cluster: `2025-04-15 → 2025-05-14`

Sign-flip counts (11 windows → 10 transitions):
- `custom/benchmark`: **6 flips** (all simulators)
- `custom/hrp`: **3–4 flips** (cvxportfolio slightly fewer flips than custom/nautilus)
- Baseline `raw_pool_ew`: **6 flips** (custom/nautilus) and **8 flips** (cvxportfolio)
- Baseline `market`: **2 flips**

Interpretation: `temporal_fragility` is not being driven by a single bad window; it is being driven by **repeated sign-flips** plus very large Sharpe deltas between adjacent windows.

### 6.7 Ledger correlation: sign flips coincide with universe/weight discontinuities
We correlated the largest flip transition (`2025-05-14 → 2025-06-12`) to the audit ledger’s per-window optimize outputs:

- `engine=custom, profile=benchmark`:
  - window ending `2025-05-14`: `n_assets=4` with equal-weight holdings including `AMEX:SPY`
  - window ending `2025-06-12`: `n_assets=6` and the appearance of `BINANCE:BONKUSDT` in the holdings set
- `engine=custom, profile=hrp`:
  - window ending `2025-05-14`: `n_assets=4` (high concentration; max weight ≈ 1/3)
  - window ending `2025-06-12`: `n_assets=6` and `BINANCE:BONKUSDT` becomes the dominant holding (~1/3)
- Baseline `engine=market, profile=raw_pool_ew`:
  - `n_assets=19` and equal weights were **stable across the same transition**

Evidence source: `artifacts/summaries/runs/20260105-154839/audit.jsonl` `backtest_optimize` outcomes with `context.window_index` corresponding to the `end_date` ordering in `grand_4d_tournament_results.json`.

Interpretation: for non-baseline strategies, the largest sign-flip window is associated with an abrupt shift to a very small universe and the inclusion of a high-volatility crypto asset, which is consistent with unstable 20d-window Sharpe behavior.

## 7. Log Review (Smoke Hygiene)
`logs/grand_4d_tournament.log` contains no:
- `ERROR`, `Traceback`, `Exception`
- `warning`, `fallback`, `parity`, or `n=2` signatures

It does contain repeated selection veto messages (`Vetoing …`), which are expected under v3.2 predictability veto logic and are not a strict-scoreboard failure by themselves.

## 8. Gate calibration proposal (test_window=20, percentile-based)
This run indicates the strict `max_temporal_fragility=1.5` gate is too tight for 20d windows: even the baseline `market` row has median fragility ~1.76–2.50 across recent production-parity smokes, and `raw_pool_ew` can enter a “CV blow-up” regime where the metric becomes extreme due to near-zero mean Sharpe.

Percentile reference approach (recommended):
1. For each recent production-parity smoke run that produces a scoreboard, extract baseline `temporal_fragility` for:
   - `engine=market, profile=market` and
   - `engine=market, profile=raw_pool_ew`,
   using the **median across simulators** for each baseline per run.
2. Compute a robust threshold using percentiles and a margin:
   - Let `F_mkt = p95(market_tf_median_over_runs)`
   - Let `F_raw = p95(raw_pool_ew_tf_median_over_runs_filtered)` where the filtered set excludes CV blow-up runs (e.g., `raw_pool_ew_tf_median > 5`)
   - Proposed: `max_temporal_fragility_20d = max(F_mkt, F_raw) + margin`

Observed (last ~8 scoreboard-capable runs, Jan 2026):
- `p95(market_tf_median) ≈ 2.5030`
- `p95(raw_pool_ew_tf_median <= 5) ≈ 1.6777`

With a conservative margin `+0.25`:
- `max_temporal_fragility_20d ≈ 2.7530`

Interpretation:
- `raw_pool_ew` is treated as a **calibration signal** (baseline stability of a broad EW universe).
- CV blow-up behavior is treated as a **sentinel**, not a reason to permanently loosen the gate into double digits.

## 9. Issues to Fix (Strict-Scoreboard Oriented)

### P0 — Candidate starvation (no strict candidates)
- Symptom: `tournament_candidates.csv` empty.
- Evidence: `artifacts/summaries/runs/20260105-154839/data/tournament_candidates.csv`.
- Binding gates: first veto is dominated by `friction_decay` (9/15 rows) and `temporal_fragility` (6/15 rows); non-baseline rows also fail `af_dist` 6/6.
- Acceptance (strict): at least one non-baseline configuration appears in `tournament_candidates.csv` for a production-parity mini grid.
- Next step: decide whether the objective is to (a) tune strategies/engines to meet current institutional gates, or (b) calibrate thresholds to reflect realistic 20-day windows (calibration should be based on multiple runs, not a single smoke).

### P1 — Temporal fragility gate dominates (CV of Sharpe)
- Symptom: `temporal_fragility` fails across all non-baseline rows and all baseline rows (including baseline market).
- Evidence: `artifacts/summaries/runs/20260105-154839/data/tournament_scoreboard.csv` and per-window Sharpe in `artifacts/summaries/runs/20260105-154839/grand_4d_tournament_results.json`.
- Hypothesis: CV-based fragility is extremely sensitive when mean Sharpe is near zero and window Sharpe oscillates in sign; 20-day windows amplify Sharpe noise.
- Acceptance: either (a) a strategy/engine change that reduces Sharpe sign-flips across windows, or (b) a calibrated fragility threshold for 20-day windows that still discriminates noise-chasing but does not veto the entire grid.

### P1 — Friction alignment failure for `custom/benchmark`
- Symptom: `friction_decay ≈ 0.417` (above `0.30` threshold).
- Evidence: `artifacts/summaries/runs/20260105-154839/data/tournament_scoreboard.csv` rows where `engine=custom`, `profile=benchmark`.
- Interpretation: performance collapses between idealized simulator and high-fidelity (`cvxportfolio`) beyond institutional tolerance; investigate friction model vs strategy turnover/exposure.
- Acceptance: `friction_decay <= 0.30` for benchmark-like strategies in production-parity mini grids, or a documented rationale for a higher friction tolerance band for benchmark profiles.

### P1 — Simulator parity gate failure for `custom/hrp`
- Symptom: `parity_ann_return_gap ≈ 2.78%` (above `1.5%` gate).
- Evidence: `artifacts/summaries/runs/20260105-154839/data/tournament_scoreboard.csv` rows where `engine=custom`, `profile=hrp` (`sim_parity` in failures).
- Interpretation: `nautilus` rows match `custom` rows in this run (same annualized return and window metrics), so the parity gate is effectively measuring **cvxportfolio vs custom** for HRP and is binding.
- Acceptance: either (a) `parity_ann_return_gap < 1.5%` for HRP profiles, or (b) an upgraded nautilus parity proxy whose outputs are meaningfully independent and therefore appropriate for a strict cross-simulator gate.

### P1 — HRP turnover veto
- Symptom: `avg_turnover ≈ 0.5855` (above `0.50` threshold).
- Evidence: `artifacts/summaries/runs/20260105-154839/data/tournament_scoreboard.csv` HRP rows.
- Interpretation: churn too high for institutional implementability; investigate turnover penalties / partial rebalance / regime-scheduled rebalancing.
- Acceptance: `avg_turnover <= 0.50` for HRP (or a justified threshold change), while retaining Sharpe and antifragility gates.

### P2 — Baseline raw_pool_ew tail multipliers and parity failures
- Symptom: baseline `raw_pool_ew` row fails `cvar_mult`, `mdd_mult`, and `sim_parity`.
- Evidence: `artifacts/summaries/runs/20260105-154839/data/tournament_scoreboard.csv` rows where `engine=market`, `profile=raw_pool_ew`.
- Note: baseline failures do not necessarily indicate a bug, but they affect “baseline as hurdle” interpretation and should be tracked.

### P2 — Baseline `benchmark` duplicates `custom/benchmark` behavior
- Symptom: `engine=market`, `profile=benchmark` rows are numerically identical to `engine=custom`, `profile=benchmark` rows (same summary metrics and failures).
- Evidence: `artifacts/summaries/runs/20260105-154839/data/tournament_scoreboard.csv` rows for benchmark profiles across `engine in {custom,market}`.
- Interpretation: this may be expected if the “benchmark profile” is defined as an equal-weight baseline of the benchmark basket; if not, it can confuse “baseline vs strategy” analysis.
- Acceptance: either confirm via spec that `market/benchmark` is intentionally equivalent to `custom/benchmark`, or revise baseline construction to represent a distinct benchmark baseline.
