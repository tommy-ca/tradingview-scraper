# Specification: Immutable Audit Ledger (V1)
**Status**: Formalized
**Date**: 2025-12-31

## 1. Overview
This document defines the requirements and implementation of the **Immutable Audit Ledger**, a system designed to ensure 100% reproducibility and cryptographic integrity of the quantitative production pipeline. It moves the platform from passive logging to an active "Decision Ledger" that links every output to its specific input data and configuration.

**Crucially, the Audit Ledger (`audit.jsonl`) serves as the System of Record for all downstream reporting.** Reports are generated by replaying and extracting structured data directly from the ledger, ensuring that the reported metrics match exactly what was cryptographically committed during execution.

## 2. Core implementation

### 2.1 Write-Ahead Logging (WAL) Principle
Every significant pipeline step records its **Intent** (Inputs + Parameters) before execution and its **Outcome** (Results + Artifact Hashes + Structured Data) after completion. This is managed by the `AuditLedger` class in `tradingview_scraper/utils/audit.py`.

### 2.2 Cryptographic Chaining
- Log entries are chained using SHA-256 hashes.
- Each record contains a `prev_hash` field referencing the hash of the previous line.
- The `hash` of the current record is calculated over the entire JSON content (canonicalized) + the `prev_hash`.
- The ledger is stored as `audit.jsonl` in the run directory.

### 2.3 Deterministic Data Hashing (`df_hash`)
- The system implements `get_df_hash` to compute stable signatures of Pandas DataFrames.
- **Determinism**: Shuffling rows or columns does not change the hash.
- **Lineage**: Ensures that the exact returns matrix used for a backtest is identifiable and untampered.

### 2.4 Rich Data Payloads
To support self-contained reporting, critical steps must log rich structured data in their `outcome.data` field:
- **Natural Selection**: Logs the full selection state:
    - `spec_version`: Explicit version used ('1.0', '2.0', '3.0').
    - `vetoes`: Dictionary mapping symbols to specific disqualification reasons (e.g., "Missing metadata", "High ECI").
    - `engine_metrics`: Version-specific quantitative context (e.g., `kappa`, `avg_eci`, individual `alpha_scores`).
    - `audit_clusters`: Detailed mapping of symbol survival per cluster.
- **Clustering**: Logs the simplified `portfolio_clusters` map.
- **Tournament**: Logs the full multi-engine result summary.

### 2.5 Verification Tool
A standalone utility `scripts/verify_ledger.py` is provided to "replay" the audit chain and detect any tampering or inconsistencies in the record.

## 3. Data Schema

### 3.1 Genesis Block
```json
{
  "type": "genesis",
  "run_id": "20251231-150000",
  "ts": "2025-12-31T15:00:00Z",
  "env": {
    "git_sha": "a1b2c3d...",
    "python_v": "3.12.x",
    "manifest_hash": "sha256..."
  },
  "hash": "..."
}
```

### 3.2 Action Entry
```json
{
  "type": "action",
  "step": "natural_selection",
  "status": "success",
  "intent": { ... },
  "outcome": {
    "output_hashes": { "candidates": "sha256..." },
    "metrics": { "n_winners": 32 },
    "data": {
        "selection": { "total_raw_symbols": 80, "total_selected": 32, ... },
        "portfolio_clusters": { "1": ["AAPL", "MSFT"], ... }
    }
  },
  "prev_hash": "...",
  "hash": "..."
}
```

### 3.3 Tournament Complete Entry
```json
{
  "type": "action",
  "step": "tournament_complete",
  "status": "success",
  "outcome": {
    "data": {
        "tournament_summary": { ... full result hierarchy ... },
        "meta": { ... }
    }
  }
}
```

## 4. Pipeline Integration Points

| Stage | Audit Evidence Captured (Structured Metrics & Data) |
| :--- | :--- |
| **Discovery** | `n_discovery_files`: Count of non-empty JSON result files. |
| **Pruning** | `n_selected_symbols`: Number of leaders. **Payload**: Full Selection State & Cluster Map. |
| **Alignment** | Count of gap-filled candles, Hash of final 500d returns matrix. |
| **Health Audit** | `n_missing`, `n_stale`, `n_degraded`: Detailed counts of problematic assets. |
| **Recovery** | `trigger`: Evidence of failure that necessitated a recovery pass. |
| **Optimization** | `optimized_profiles`: List of profiles successfully generated. |
| **Tournament** | Per-window hashes. **Payload**: Final Tournament Summary. |

## 6. Concurrency & Nesting
The Audit Ledger supports nested and concurrent processes by reloading the `last_hash` from disk before every append operation. This ensures that sub-scripts (e.g., `natural_selection.py`) can contribute to the main `audit.jsonl` without breaking the cryptographic chain managed by the orchestrator.

## 5. Verification
A standalone utility `scripts/verify_ledger.py` will be provided to:
1. Recompute the hash chain to detect tampering.
2. Verify that the current `data/lakehouse` artifacts match the hashes recorded in the ledger.
3. Report any "unexplained" deviations in the implementation universe.
