# Design: Natural Selection Benchmarking & Alpha Isolation

## 1. Objective
To provide a mathematical and logical framework for quantifying the performance impact of the Natural Selection engines (V2 and V3). By isolating the returns generated by "Selection" from those generated by "Optimization," we can validate whether our Darwinian vetoes (V3) improve implementation outcomes.

## 2. The Alpha Hierarchy

We decompose the total strategy return ($R_{total}$) into three additive components:

$$ R_{total} = R_{base} + \alpha_{selection} + \alpha_{optimization} $$

Where:
- **$R_{base}$ (Market Baseline)**: Returns from a fixed institutional benchmark (e.g., SPY).
- **$\alpha_{selection}$ (Pruning Alpha)**: The value added by moving from the **Raw Discovery Pool** to the **Filtered Universe**.
- **$\alpha_{optimization}$ (Weighting Alpha)**: The value added by moving from **Equal Weighting** to **Risk-Aware Weighting** (e.g., MinVar, HRP).

### 2.1 Calculating Selection Alpha ($A_s$)
Selection Alpha measures the quality of the pruning logic.

$$ A_s = \frac{1}{N_f} \sum_{i \in \mathcal{F}} r_i - \frac{1}{N_r} \sum_{j \in \mathcal{R}} r_j $$

- $\mathcal{R}$: The set of all raw discovered candidates ($N_r$).
- $\mathcal{F}$: The set of candidates surviving the Selection Spec ($N_f$).
- $r$: Realized asset returns.

### 2.2 Calculating Optimization Alpha ($A_o$)
Optimization Alpha measures the quality of the weighting engine.

$$ A_o = \sum_{i \in \mathcal{F}} w_i r_i - \frac{1}{N_f} \sum_{i \in \mathcal{F}} r_i $$

- $w_i$: Optimized weights assigned by the portfolio engine.

## 3. V3 Veto Impact Quantification

Selection Engine V3 introduces hard vetoes. We quantify their efficiency using **Veto Avoidance Decay**:

1. **Veto Precision**: % of vetoed assets that realized a negative Sharpe or a >20% drawdown in the subsequent test window.
2. **ECI Alpha Protection**: The spread in net returns (post-slippage) between a universe with ECI gates (V3) and one without (V2).
3. **Condition Number ($\kappa$) Stability**: Tracking solver failure rates and weight instability as a function of the input $\kappa$ recorded in the audit ledger.

## 4. Tournament Integration (Feature Flag Logic)

The 4D Tournament Matrix is activated via the `feat_multi_selection_tournament` flag. When enabled, the `BacktestEngine` iterates through selection profiles that have their respective feature flags set to `True`.

1. **Check Flags**: Resolve active profiles:
    - `Darwinian` (enabled via `feat_selection_darwinian`).
    - `Robust` (enabled via `feat_selection_robust`).
    - `Relative` (V2 baseline).
2. **Execute Loop**: For each walk-forward window, run selection for each active profile.
3. **Record Metrics**: Append `selection_spec`, `kappa`, `avg_eci`, and `veto_count` to the audit record for each window/spec combination.
4. **Fast-Track Toggle**: If `feat_fast_tournament` is enabled, the engine only runs the primary `Darwinian` spec unless others are explicitly requested.

## 5. Reporting

The final benchmark report will include a "Selection Efficiency Matrix":

| Selection Spec | Mean $A_s$ | Hit Rate | Mean $\kappa$ | Mean ECI | Total $\alpha$ |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Darwinian (V3)** | +45bps | 62% | $1.2e4$ | 12bps | +112bps |
| **Relative (V2)** | +22bps | 51% | $5.8e7$ | 45bps | +88bps |
